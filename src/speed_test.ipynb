{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation</h1>\n",
    "<h3>this script for test model speed</h3>\n",
    "<h3>check speed only .pt files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.116 🚀 Python-3.10.9 torch-2.0.0 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/dataset/valid.cache... 62885 images, 2636 backgrounds, 0 corrupt: 100%|██████████| 62933/62933 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3934/3934 [05:56<00:00, 11.02it/s]\n",
      "                   all      62933     785043      0.725      0.577      0.642      0.415\n",
      "                person      62933     435032      0.788      0.655      0.734      0.459\n",
      "                   car      62933     348796      0.821      0.751      0.826        0.6\n",
      "                fallen      62933       1215      0.564      0.323      0.366      0.185\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/yolov8/runs/detect/val2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7f43a2b4a080>\n",
       "fitness: 0.4374295200980461\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.4592,     0.60011,     0.18483])\n",
       "names: {0: 'person', 1: 'car', 2: 'fallen'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.7245016577973199, 'metrics/recall(B)': 0.5765127027753232, 'metrics/mAP50(B)': 0.6418884575198979, 'metrics/mAP50-95(B)': 0.41471186038450697, 'fitness': 0.4374295200980461}\n",
       "save_dir: PosixPath('/workspace/yolov8/runs/detect/val2')\n",
       "speed: {'preprocess': 0.05803886666218431, 'inference': 0.6964345087667212, 'loss': 0.0006148163276286729, 'postprocess': 0.6149984725584335}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/workspace/yolov8/runs/detect/train11/weights/best.pt')\n",
    "\n",
    "model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/workspace/yolov8/ultralytics/datasets/engine_dataset.yaml, weights=['/workspace/yolov8/yolov5_best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.9 torch-2.0.0 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/home/unicomnet/docker/labeling_data/new_dataset/valid... 570\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/home/unicomnet/docker/labeling_data/new_dataset/valid.cache\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      57034     770892      0.945      0.837      0.909      0.706\n",
      "                person      57034     424028      0.924      0.788       0.87      0.618\n",
      "                   car      57034     346864      0.965      0.886      0.948      0.794\n",
      "Speed: 0.0ms pre-process, 3.6ms inference, 0.6ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5/runs/val/exp2\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!python /workspace/yolov5/val.py --weights /workspace/yolov8/yolov5_best.pt --data /workspace/yolov8/ultralytics/datasets/engine_dataset.yaml --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.117 🚀 Python-3.10.9 torch-2.0.0 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "YOLOv8_custom summary (fused): 218 layers, 25840918 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "\nDataset '/workspace/yolov8/dev/datasets/coco2017.yaml' images not found ⚠️, missing paths ['/data/YOLO/validataion']\nNote dataset download directory is '/workspace/datasets'. You can update this in '/root/.config/Ultralytics/settings.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39multralytics\u001b[39;00m \u001b[39mimport\u001b[39;00m YOLO\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m'\u001b[39m\u001b[39m/workspace/yolov8/dev/results/m_model_epoch3_batch32/weights/best.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m model\u001b[39m.\u001b[39;49mval(data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/workspace/yolov8/dev/datasets/coco2017.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:302\u001b[0m, in \u001b[0;36mYOLO.val\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m args\u001b[39m.\u001b[39mimgsz \u001b[39m=\u001b[39m check_imgsz(args\u001b[39m.\u001b[39mimgsz, max_dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    301\u001b[0m validator \u001b[39m=\u001b[39m TASK_MAP[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask][\u001b[39m2\u001b[39m](args\u001b[39m=\u001b[39margs, _callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[0;32m--> 302\u001b[0m validator(model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel)\n\u001b[1;32m    303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m validator\u001b[39m.\u001b[39mmetrics\n\u001b[1;32m    305\u001b[0m \u001b[39mreturn\u001b[39;00m validator\u001b[39m.\u001b[39mmetrics\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/validator.py:127\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    124\u001b[0m         LOGGER\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mForcing batch=1 square inference (1,3,\u001b[39m\u001b[39m{\u001b[39;00mimgsz\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mimgsz\u001b[39m}\u001b[39;00m\u001b[39m) for non-PyTorch models\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.yaml\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m check_det_dataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    128\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtask \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclassify\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m check_cls_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata, split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msplit)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/data/utils.py:251\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     m \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mNote dataset download directory is \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mDATASETS_DIR\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. You can update this in \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mSETTINGS_YAML\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(m)\n\u001b[1;32m    252\u001b[0m t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m s\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m s\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# URL\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset '/workspace/yolov8/dev/datasets/coco2017.yaml' images not found ⚠️, missing paths ['/data/YOLO/validataion']\nNote dataset download directory is '/workspace/datasets'. You can update this in '/root/.config/Ultralytics/settings.yaml'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/workspace/yolov8/dev/results/m_model_epoch3_batch32/weights/best.pt')\n",
    "\n",
    "model.val(data='/workspace/yolov8/dev/datasets/coco2017.yaml', device=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
