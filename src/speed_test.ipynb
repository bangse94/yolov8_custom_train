{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation</h1>\n",
    "<h3>this script for test model speed</h3>\n",
    "<h3>check speed only .pt files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python /workspace/yolov5/val.py --weights /workspace/yolov8/yolov5_best.pt --data /workspace/yolov8/ultralytics/datasets/engine_dataset.yaml --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.120 ðŸš€ Python-3.10.9 torch-2.0.0 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "                                                      CUDA:1 (NVIDIA RTX A5000, 24248MiB)\n",
      "                                                      CUDA:2 (NVIDIA RTX A5000, 24248MiB)\n",
      "                                                      CUDA:3 (NVIDIA RTX A5000, 24248MiB)\n",
      "YOLOv8 summary (fused): 218 layers, 25886080 parameters, 0 gradients, 78.9 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/home/unicomnet/docker/labeling_data/new_dataset/cocolabels.cache... 57034 images, 525 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57034/57034 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223/223 [07:00<00:00,  1.88s/it]\n",
      "                   all      57034     770892        0.7      0.409      0.483      0.286\n",
      "                person      57034     424028      0.738      0.374      0.464      0.266\n",
      "                   car      57034     346864      0.662      0.444      0.503      0.306\n",
      "Speed: 0.1ms preprocess, 2.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/yolov8/runs/detect/val3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 2])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7ef9b70a4ac0>\n",
       "fitness: 0.30598218440119745\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.26633,     0.28629,     0.30625,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,\n",
       "           0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,\n",
       "           0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,\n",
       "           0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629,     0.28629])\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.7001369383775775, 'metrics/recall(B)': 0.40905828554978996, 'metrics/mAP50(B)': 0.4832236844182507, 'metrics/mAP50-95(B)': 0.2862886843993026, 'fitness': 0.30598218440119745}\n",
       "save_dir: PosixPath('/workspace/yolov8/runs/detect/val3')\n",
       "speed: {'preprocess': 0.07552033274656227, 'inference': 2.9377214921224324, 'loss': 4.4892119103897314e-05, 'postprocess': 0.813442167453396}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/workspace/yolov8/runs/detect/train7/weights/best.pt')\n",
    "\n",
    "model.val(data='/workspace/yolov8/dev/datasets/2class_validation_coco.yaml', device='0,1,2,3', batch=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.120 ðŸš€ Python-3.10.9 torch-2.0.0 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "                                                      CUDA:1 (NVIDIA RTX A5000, 24248MiB)\n",
      "                                                      CUDA:2 (NVIDIA RTX A5000, 24248MiB)\n",
      "                                                      CUDA:3 (NVIDIA RTX A5000, 24248MiB)\n",
      "YOLOv8_2class summary (fused): 218 layers, 25840918 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/home/unicomnet/docker/labeling_data/new_dataset/valid.cache... 57034 images, 525 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57034/57034 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223/223 [06:52<00:00,  1.85s/it]\n",
      "                   all      57034     770892      0.711      0.421      0.495      0.292\n",
      "                person      57034     424028      0.752      0.399      0.483      0.283\n",
      "                   car      57034     346864       0.67      0.442      0.506      0.302\n",
      "Speed: 0.1ms preprocess, 2.9ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/yolov8/runs/detect/val4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7efb6fd19ea0>\n",
       "fitness: 0.31242496182515755\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.28284,     0.30151])\n",
       "names: {0: 'person', 1: 'car'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.7111368072694392, 'metrics/recall(B)': 0.4209436260394668, 'metrics/mAP50(B)': 0.4946731132758871, 'metrics/mAP50-95(B)': 0.29217516721952097, 'fitness': 0.31242496182515755}\n",
       "save_dir: PosixPath('/workspace/yolov8/runs/detect/val4')\n",
       "speed: {'preprocess': 0.07318383986800182, 'inference': 2.897915634645939, 'loss': 5.949804741649786e-05, 'postprocess': 0.6809999444739959}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/workspace/yolov8/runs/detect/train9/weights/best.pt')\n",
    "\n",
    "model.val(data='/workspace/yolov8/dev/datasets/2class_validation_mgen.yaml', device='0,1,2,3', batch=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
