{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Speed Test</h1>\n",
    "<h3>this script for test model speed</h3>\n",
    "<h3>check speed only .pt files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.116 ðŸš€ Python-3.10.9 torch-2.0.0 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/dataset/valid.cache... 62885 images, 2636 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62933/62933 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3934/3934 [05:56<00:00, 11.02it/s]\n",
      "                   all      62933     785043      0.725      0.577      0.642      0.415\n",
      "                person      62933     435032      0.788      0.655      0.734      0.459\n",
      "                   car      62933     348796      0.821      0.751      0.826        0.6\n",
      "                fallen      62933       1215      0.564      0.323      0.366      0.185\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/yolov8/runs/detect/val2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7f43a2b4a080>\n",
       "fitness: 0.4374295200980461\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.4592,     0.60011,     0.18483])\n",
       "names: {0: 'person', 1: 'car', 2: 'fallen'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.7245016577973199, 'metrics/recall(B)': 0.5765127027753232, 'metrics/mAP50(B)': 0.6418884575198979, 'metrics/mAP50-95(B)': 0.41471186038450697, 'fitness': 0.4374295200980461}\n",
       "save_dir: PosixPath('/workspace/yolov8/runs/detect/val2')\n",
       "speed: {'preprocess': 0.05803886666218431, 'inference': 0.6964345087667212, 'loss': 0.0006148163276286729, 'postprocess': 0.6149984725584335}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/workspace/yolov8/runs/detect/train11/weights/best.pt')\n",
    "\n",
    "model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/workspace/yolov8/ultralytics/datasets/engine_dataset.yaml, weights=['/workspace/yolov8/yolov5_best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v7.0-178-ga199480 Python-3.10.9 torch-2.0.0 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/home/unicomnet/docker/labeling_data/new_dataset/valid... 570\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/home/unicomnet/docker/labeling_data/new_dataset/valid.cache\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      57034     770892      0.945      0.837      0.909      0.706\n",
      "                person      57034     424028      0.924      0.788       0.87      0.618\n",
      "                   car      57034     346864      0.965      0.886      0.948      0.794\n",
      "Speed: 0.0ms pre-process, 3.6ms inference, 0.6ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5/runs/val/exp2\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!python /workspace/yolov5/val.py --weights /workspace/yolov8/yolov5_best.pt --data /workspace/yolov8/ultralytics/datasets/engine_dataset.yaml --device 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
